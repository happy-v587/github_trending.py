#!/usr/bin/env python3
"""
GitHub Trending Projects Tool
è·å–GitHubçƒ­é—¨é¡¹ç›®çš„Pythonå·¥å…·
"""

import argparse
import json
import sys
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
import requests
from bs4 import BeautifulSoup
import pandas as pd


class GitHubTrending:
    """GitHubè¶‹åŠ¿é¡¹ç›®è·å–å™¨"""
    
    def __init__(self, cache_timeout: int = 3600):
        """
        åˆå§‹åŒ–GitHubè¶‹åŠ¿è·å–å™¨
        
        Args:
            cache_timeout: ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        self.base_url = "https://github.com/trending"
        self.cache_timeout = cache_timeout
        self.cache_file = ".github_trending_cache.json"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
    
    def _load_cache(self) -> Optional[Dict[str, Any]]:
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            cache_time = cache_data.get('timestamp', 0)
            current_time = time.time()
            
            if current_time - cache_time < self.cache_timeout:
                return cache_data.get('data')
        except (FileNotFoundError, json.JSONDecodeError):
            pass
        return None
    
    def _save_cache(self, data: List[Dict[str, Any]]) -> None:
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        cache_data = {
            'timestamp': time.time(),
            'data': data
        }
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"è­¦å‘Š: ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def fetch_trending(self, language: str = "", since: str = "daily", use_cache: bool = True) -> List[Dict[str, Any]]:
        """
        è·å–GitHubè¶‹åŠ¿é¡¹ç›®
        
        Args:
            language: ç¼–ç¨‹è¯­è¨€è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
            since: æ—¶é—´èŒƒå›´ï¼ˆdaily, weekly, monthlyï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached_data = self._load_cache()
            if cached_data:
                print("ä½¿ç”¨ç¼“å­˜æ•°æ®...")
                return cached_data
        
        # æ„å»ºURL
        url = self.base_url
        params = {}
        
        if language:
            params['l'] = language
        if since:
            params['since'] = since
        
        try:
            print(f"æ­£åœ¨è·å–GitHubè¶‹åŠ¿æ•°æ®...")
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            projects = self._parse_projects(soup)
            
            # ä¿å­˜ç¼“å­˜
            self._save_cache(projects)
            
            return projects
            
        except requests.RequestException as e:
            print(f"è¯·æ±‚å¤±è´¥: {e}")
            # å°è¯•ä½¿ç”¨ç¼“å­˜
            cached_data = self._load_cache()
            if cached_data:
                print("ä½¿ç”¨ç¼“å­˜æ•°æ®...")
                return cached_data
            return []
    
    def _parse_projects(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """è§£æHTMLè·å–é¡¹ç›®ä¿¡æ¯"""
        projects = []
        
        # æŸ¥æ‰¾é¡¹ç›®åˆ—è¡¨
        articles = soup.find_all('article', class_='Box-row')
        
        for article in articles:
            try:
                # æå–é¡¹ç›®åç§°å’Œé“¾æ¥
                title_elem = article.find('h2', class_='h3')
                if not title_elem:
                    continue
                    
                link_elem = title_elem.find('a')
                if not link_elem:
                    continue
                    
                repo_name = link_elem.get('href', '').strip('/')
                repo_url = f"https://github.com{link_elem.get('href', '')}"
                
                # æå–æè¿°
                desc_elem = article.find('p', class_='col-9')
                description = desc_elem.text.strip() if desc_elem else ""
                
                # æå–ç¼–ç¨‹è¯­è¨€
                lang_elem = article.find('span', itemprop='programmingLanguage')
                language = lang_elem.text.strip() if lang_elem else "Unknown"
                
                # æå–æ˜Ÿæ ‡æ•°
                stars_elem = article.find('a', href=lambda x: x and 'stargazers' in x)
                stars_text = stars_elem.text.strip() if stars_elem else "0"
                stars = self._parse_number(stars_text)
                
                # æå–ä»Šæ—¥æ˜Ÿæ ‡æ•°
                stars_today_elem = article.find('span', class_='d-inline-block float-sm-right')
                stars_today_text = stars_today_elem.text.strip() if stars_today_elem else "0"
                stars_today = self._parse_number(stars_today_text.split()[0] if stars_today_text else "0")
                
                # æå–forkæ•°
                forks_elem = article.find('a', href=lambda x: x and 'forks' in x)
                forks_text = forks_elem.text.strip() if forks_elem else "0"
                forks = self._parse_number(forks_text)
                
                project = {
                    'rank': len(projects) + 1,
                    'name': repo_name,
                    'url': repo_url,
                    'description': description,
                    'language': language,
                    'stars': stars,
                    'stars_today': stars_today,
                    'forks': forks,
                    'timestamp': datetime.now().isoformat()
                }
                
                projects.append(project)
                
            except Exception as e:
                print(f"è§£æé¡¹ç›®æ—¶å‡ºé”™: {e}")
                continue
        
        return projects
    
    def _parse_number(self, text: str) -> int:
        """è§£ææ•°å­—å­—ç¬¦ä¸²ï¼ˆå¤„ç†kã€Mç­‰å•ä½ï¼‰"""
        text = text.lower().replace(',', '')
        
        if 'k' in text:
            return int(float(text.replace('k', '')) * 1000)
        elif 'm' in text:
            return int(float(text.replace('m', '')) * 1000000)
        
        try:
            return int(float(text))
        except ValueError:
            return 0
    
    def print_summary(self, projects: List[Dict[str, Any]], limit: int = 10) -> None:
        """æ‰“å°é¡¹ç›®æ‘˜è¦"""
        if not projects:
            print("æœªæ‰¾åˆ°ä»»ä½•é¡¹ç›®")
            return
        
        print(f"\n{'='*80}")
        print(f"GitHubçƒ­é—¨é¡¹ç›® ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
        print(f"{'='*80}")
        
        # æŒ‰ä»Šæ—¥æ˜Ÿæ ‡æ•°æ’åº
        sorted_projects = sorted(projects, key=lambda x: x['stars_today'], reverse=True)
        
        for i, project in enumerate(sorted_projects[:limit], 1):
            print(f"\n{i:2d}. {project['name']}")
            print(f"    ğŸ“ {project['description'][:100]}{'...' if len(project['description']) > 100 else ''}")
            print(f"    ğŸ”¤ è¯­è¨€: {project['language']}")
            print(f"    â­ æ€»æ˜Ÿæ ‡: {project['stars']:,} | ä»Šæ—¥æ–°å¢: {project['stars_today']:,}")
            print(f"    ğŸ´ Forkæ•°: {project['forks']:,}")
            print(f"    ğŸ”— {project['url']}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*80}")
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"    â€¢ æ€»é¡¹ç›®æ•°: {len(projects)}")
        
        # è¯­è¨€åˆ†å¸ƒ
        languages = {}
        for project in projects:
            lang = project['language']
            languages[lang] = languages.get(lang, 0) + 1
        
        top_languages = sorted(languages.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"    â€¢ çƒ­é—¨è¯­è¨€: {', '.join([f'{lang}({count})' for lang, count in top_languages])}")
        
        # ä»Šæ—¥æœ€ç«é¡¹ç›®
        if projects:
            top_project = max(projects, key=lambda x: x['stars_today'])
            print(f"    â€¢ ä»Šæ—¥æœ€ç«: {top_project['name']} (+{top_project['stars_today']:,}â­)")
        
        print(f"{'='*80}")
    
    def export_to_csv(self, projects: List[Dict[str, Any]], filename: str = "github_trending.csv") -> None:
        """å¯¼å‡ºåˆ°CSVæ–‡ä»¶"""
        if not projects:
            print("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
        
        df = pd.DataFrame(projects)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
    
    def export_to_json(self, projects: List[Dict[str, Any]], filename: str = "github_trending.json") -> None:
        """å¯¼å‡ºåˆ°JSONæ–‡ä»¶"""
        if not projects:
            print("æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(projects, f, ensure_ascii=False, indent=2)
        print(f"æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='è·å–GitHubçƒ­é—¨é¡¹ç›®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                          # è·å–ä»Šæ—¥çƒ­é—¨é¡¹ç›®
  %(prog)s --language python        # è·å–Pythoné¡¹ç›®
  %(prog)s --since weekly           # è·å–æœ¬å‘¨çƒ­é—¨
  %(prog)s --limit 20               # æ˜¾ç¤º20ä¸ªé¡¹ç›®
  %(prog)s --export csv             # å¯¼å‡ºä¸ºCSV
  %(prog)s --no-cache               # ä¸ä½¿ç”¨ç¼“å­˜
  %(prog)s --all                    # æ˜¾ç¤ºæ‰€æœ‰é¡¹ç›®
        """
    )
    
    parser.add_argument('--language', '-l', type=str, default='',
                       help='ç¼–ç¨‹è¯­è¨€è¿‡æ»¤ (å¦‚: python, javascript, go)')
    parser.add_argument('--since', '-s', type=str, default='daily',
                       choices=['daily', 'weekly', 'monthly'],
                       help='æ—¶é—´èŒƒå›´: daily(ä»Šæ—¥), weekly(æœ¬å‘¨), monthly(æœ¬æœˆ)')
    parser.add_argument('--limit', '-n', type=int, default=10,
                       help='æ˜¾ç¤ºé¡¹ç›®æ•°é‡ (é»˜è®¤: 10)')
    parser.add_argument('--export', '-e', type=str, choices=['csv', 'json', 'both'],
                       help='å¯¼å‡ºæ ¼å¼: csv, json, both')
    parser.add_argument('--no-cache', action='store_true',
                       help='ä¸ä½¿ç”¨ç¼“å­˜')
    parser.add_argument('--all', '-a', action='store_true',
                       help='æ˜¾ç¤ºæ‰€æœ‰é¡¹ç›®')
    parser.add_argument('--quiet', '-q', action='store_true',
                       help='å®‰é™æ¨¡å¼ï¼Œåªè¾“å‡ºæ•°æ®')
    
    args = parser.parse_args()
    
    # åˆ›å»ºGitHubè¶‹åŠ¿è·å–å™¨
    trending = GitHubTrending()
    
    # è·å–æ•°æ®
    projects = trending.fetch_trending(
        language=args.language,
        since=args.since,
        use_cache=not args.no_cache
    )
    
    if not projects:
        print("é”™è¯¯: æ— æ³•è·å–GitHubè¶‹åŠ¿æ•°æ®")
        sys.exit(1)
    
    # è®¾ç½®æ˜¾ç¤ºé™åˆ¶
    limit = None if args.all else args.limit
    
    # è¾“å‡ºç»“æœ
    if not args.quiet:
        trending.print_summary(projects, limit=limit if limit else len(projects))
    
    # å¯¼å‡ºæ•°æ®
    if args.export:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if args.export in ['csv', 'both']:
            filename = f"github_trending_{timestamp}.csv"
            trending.export_to_csv(projects, filename)
        
        if args.export in ['json', 'both']:
            filename = f"github_trending_{timestamp}.json"
            trending.export_to_json(projects, filename)
    
    # åœ¨å®‰é™æ¨¡å¼ä¸‹åªè¾“å‡ºJSON
    if args.quiet:
        print(json.dumps(projects, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()